* ¿Cómo afecta la cantidad de parámetros del modelo? ¿Qué nos dicen eso 9M de parametros del modelo que hemos creado?
Lo que afecta la cantidad de parametros del modelo es a la capacidad de aprender patrones complejos. 9M de parametros en un modelo es bastante grande y esto indica que es capaz de tomar relaciones complejas dentro de los datos.

* ¿Qué hace el algoritmo de inicialización de Xavier Uniform?
Lo que hace es establecer los pesos iniciales de la red para que la varianza de activación se quede estable entre las capas. Lo que puede ayudar a los problemas de desaparición de gradiente, entonces la red se entrena de una mejor manera, ya que es más eficaz y práctico.

* ¿Qué hace el comando torch.no_grad()?
Este es un administrador de contexto que deshabilita el cálculo de gradiente. Entonces deshabilita el cálculo del gradiente, esto es útil para la inferencia, cuando no se está seguro de llamar a Tensor.backward, entonces esto reduce el consumo de memoria para cálculos que tendrían requires_grad=True.

* Interprete el valor obtenido para el BLEU score ¿es nuestro modelo un buen modelo?
El valor obtenido de BLEU score es de 35.72 lo que nos indica un desempeño decente en cuanto la traducción y que el modelo puede generar secuencias de palabras que son similares a las secuencias de palabras esperadas. 

* ¿Qué puede observar de las palabras donde el modelo se ha confundido?


* Observe el comportamiento de la pérdida y PPL en training y validation mientras se entrega el modelo, ¿qué puede decir de estos valores?


* Si bien no es una tarea intuitiva o sencilla la interpretación de las gráficas de attention que hemos realizado, intente darle una interpretación a la última de estas gráficas mostrada. ¿Qué tipo de insights podría sacar de esta gráfica?


